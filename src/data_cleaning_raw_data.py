# -*- coding: utf-8 -*-
"""data_cleaning_raw_data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vcSH2j1J5K7YJHK00EDTYALH1BAxNsn8
"""

# Installing important libraries & Importing from them.
!apt-get -y install postgresql postgresql-contrib > /dev/null
!service postgresql start
!sudo -u postgres psql -c "ALTER USER postgres WITH PASSWORD 'mypassword';"
!pg_isready
!pip install rapidfuzz
!pip install --upgrade pip
!pip install rapidfuzz==3.6.1
import re
import pandas as pd
from rapidfuzz import fuzz
import random
import numpy as np
from sqlalchemy import create_engine, text
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity
!pip install flask pyngrok --quiet
from flask import Flask, render_template_string, request, redirect, url_for
from pyngrok import ngrok

# ============================================================
# 1. I created and populated the rawitems table in PostgreSQL
# ============================================================

def create_rawitems_table(engine):
    """
    I created the rawitems table to store the original records exactly as they came from stores.
    """
    ddl = """
    DROP TABLE IF EXISTS rawitems;

    CREATE TABLE rawitems (
        "Store_Name"   VARCHAR(20),
        "Store_Item_ID" INT,
        "POSCode"      VARCHAR(50),
        "ItemName"     VARCHAR(255),
        "Brand"        VARCHAR(100),
        "PackSize"     VARCHAR(50),
        "Category"     VARCHAR(100)
    );
    """
    with engine.begin() as conn:
        conn.execute(text(ddl))

create_rawitems_table(engine)

# I combined all three store datasets and loaded them into rawitems.
all_stores = pd.concat([store1_df, store2_df, store3_df], ignore_index=True)
all_stores.to_sql("rawitems", engine, if_exists="append", index=False)

# ============================================================
# 2. I built itemmaster_initial with cleaned attributes
# ============================================================

def build_itemmaster_initial(engine):
    """
    I created the ItemMaster_Initial table with a surrogate raw_item_id and
    added cleaned versions of key descriptive attributes.
    """
    sql = """
    DROP TABLE IF EXISTS itemmaster_initial;

    CREATE TABLE itemmaster_initial AS
    SELECT
        "Store_Name",
        "Store_Item_ID",
        "POSCode",
        "ItemName",
        "Brand",
        "PackSize",
        "Category",
        row_number() OVER ()::int AS raw_item_id
    FROM rawitems;

    ALTER TABLE itemmaster_initial
      ADD PRIMARY KEY (raw_item_id);

    ALTER TABLE itemmaster_initial
      ADD COLUMN clean_item_name VARCHAR(200),
      ADD COLUMN clean_brand     VARCHAR(100),
      ADD COLUMN clean_pack_size VARCHAR(50),
      ADD COLUMN clean_category  VARCHAR(100);
    """
    with engine.begin() as conn:
        conn.execute(text(sql))

    # I applied SQL-based cleaning to standardize the text fields.
    cleaning_sql = r"""
    UPDATE itemmaster_initial
    SET
      clean_item_name = UPPER(
          regexp_replace(
              regexp_replace("ItemName", '[^A-Za-z0-9& ]', ' ', 'g'),
              '\s+',
              ' ',
              'g'
          )
      ),
      clean_brand = UPPER(
          regexp_replace(
              regexp_replace("Brand", '[^A-Za-z0-9& ]', ' ', 'g'),
              '\s+',
              ' ',
              'g'
          )
      ),
      clean_pack_size = UPPER(
          regexp_replace(
              regexp_replace("PackSize", '[^A-Za-z0-9& ]', ' ', 'g'),
              '\s+',
              ' ',
              'g'
          )
      ),
      clean_category = UPPER(
          regexp_replace(
              regexp_replace("Category", '[^A-Za-z0-9& ]', ' ', 'g'),
              '\s+',
              ' ',
              'g'
          )
      );
    """
    with engine.begin() as conn:
        conn.execute(text(cleaning_sql))

build_itemmaster_initial(engine)

# ============================================================
# 3. I clustered items and built central_item_master
# ============================================================

def cluster_and_build_item_master(engine):
    """
    I used TF-IDF and agglomerative clustering to group similar items
    across stores into clusters and then used those clusters to build
    a central item master.
    """
    df = pd.read_sql("SELECT * FROM itemmaster_initial", engine)

    raw_id_col = "raw_item_id"
    clean_name_col = "clean_item_name"
    clean_brand_col = "clean_brand"
    clean_pack_col = "clean_pack_size"
    clean_cat_col = "clean_category"

    def normalize_item_name(s: str) -> str:
        """
        I normalized item names to reduce noise in clustering.
        """
        if not isinstance(s, str):
            return ""
        s = s.upper()
        s = " ".join(s.split())
        return s

    df["normalized_name"] = df[clean_name_col].apply(normalize_item_name)

    # I created a combined text field that included normalized name, brand, and pack size.
    df["combined"] = (
        df["normalized_name"].fillna("")
        + " "
        + df[clean_brand_col].fillna("")
        + " "
        + df[clean_pack_col].fillna("")
    )

    # I converted the combined text into TF-IDF vectors and computed cosine similarity.
    tfidf = TfidfVectorizer().fit_transform(df["combined"])
    sim_matrix = cosine_similarity(tfidf)
    dist_matrix = 1 - sim_matrix

    # I enforced hard blocking: items with different brand or pack size do not cluster together.
    brand_arr = df[clean_brand_col].fillna("").values
    pack_arr = df[clean_pack_col].fillna("").values

    brand_diff = brand_arr[:, None] != brand_arr[None, :]
    pack_diff = pack_arr[:, None] != pack_arr[None, :]
    must_separate = brand_diff | pack_diff

    dist_matrix[must_separate] = 1.0
    np.fill_diagonal(dist_matrix, 0.0)

    # I ran agglomerative clustering on the precomputed distance matrix.
    model = AgglomerativeClustering(
        n_clusters=None,
        metric="precomputed",
        linkage="average",
        distance_threshold=0.35,
    )
    df["clusterid"] = model.fit_predict(dist_matrix) + 1

    # I derived a canonical category per cluster using majority voting.
    def pick_canonical_category(group: pd.DataFrame) -> str:
        counts = group[clean_cat_col].value_counts(dropna=True)
        if len(counts) == 0:
            return "UNKNOWN"
        return counts.idxmax()

    cluster_cat = (
        df.groupby("clusterid")
        .apply(pick_canonical_category)
        .rename("cluster_category")
        .reset_index()
    )
    df = df.merge(cluster_cat, on="clusterid", how="left")
    df[clean_cat_col] = df["cluster_category"]

    # I enforced one master category per canonical brand.
    df["canonical_brand"] = df[clean_brand_col]

    def pick_brand_master_category(group: pd.DataFrame) -> str:
        counts = group[clean_cat_col].value_counts(dropna=True)
        if len(counts) == 0:
            return "UNKNOWN"
        return counts.idxmax()

    brand_cat = (
        df.groupby("canonical_brand")
        .apply(pick_brand_master_category)
        .rename("brand_master_category")
        .reset_index()
    )
    df = df.merge(brand_cat, on="canonical_brand", how="left")
    df[clean_cat_col] = df["brand_master_category"]

    # I created the item_master_clustered table to store cluster-level assignments.
    with engine.begin() as conn:
        conn.execute(text("DROP TABLE IF EXISTS item_master_clustered;"))
        conn.execute(
            text(
                """
            CREATE TABLE item_master_clustered (
                clusterid        INT,
                raw_item_id      INT,
                clean_item_name  VARCHAR(255),
                canonical_brand  VARCHAR(100),
                clean_pack_size  VARCHAR(50),
                clean_category   VARCHAR(100)
            );
        """
            )
        )

    out = df[
        [
            "clusterid",
            raw_id_col,
            clean_name_col,
            "canonical_brand",
            clean_pack_col,
            clean_cat_col,
        ]
    ]
    out.columns = [
        "clusterid",
        "raw_item_id",
        "clean_item_name",
        "canonical_brand",
        "clean_pack_size",
        "clean_category",
    ]
    out.to_sql("item_master_clustered", engine, if_exists="append", index=False)

    # I derived the central_item_master by collapsing each cluster into one master item.
    clustered_sql = """
    DROP TABLE IF EXISTS central_item_master;

    CREATE TABLE central_item_master AS
    SELECT
        clusterid              AS "MasterID",
        MIN(clean_item_name)   AS "Master_Item_Name",
        MIN(canonical_brand)   AS "Master_Brand",
        MIN(clean_pack_size)   AS "Master_Pack_Size",
        MIN(clean_category)    AS "Master_Category",
        COUNT(*)               AS "RawItemsCount"
    FROM item_master_clustered
    GROUP BY clusterid;
    """
    with engine.begin() as conn:
        conn.execute(text(clustered_sql))

cluster_and_build_item_master(engine)

# ============================================================
# 4. I built review_queue and itemmapping tables
# ============================================================

def build_review_queue_and_mapping(engine):
    """
    I created the review_queue for single-item clusters and the itemmapping table
    to link raw items to their central master.
    """
    review_sql = """
    DROP TABLE IF EXISTS review_queue;

    CREATE TABLE review_queue AS
    SELECT
        ic.raw_item_id          AS "RawItemID",
        ic.clusterid            AS "SuggestedMasterID",
        0.0                     AS "ConfidenceScore",
        'Pending'::text         AS "Status",
        imi."Store_Name",
        imi."Store_Item_ID",
        imi."ItemName",
        imi."Brand",
        imi."PackSize",
        imi."Category",
        ic.clean_item_name,
        ic.canonical_brand      AS clean_brand,
        ic.clean_pack_size,
        ic.clean_category
    FROM (
        SELECT
            imc.*,
            COUNT(*) OVER (PARTITION BY imc.clusterid) AS cluster_size
        FROM item_master_clustered imc
    ) ic
    JOIN itemmaster_initial imi
      ON ic.raw_item_id = imi.raw_item_id
    WHERE ic.cluster_size = 1;
    """

    mapping_sql = """
    DROP TABLE IF EXISTS itemmapping;

    CREATE TABLE itemmapping AS
    SELECT
        ic.raw_item_id          AS "RawItemID",
        ic.clusterid            AS "MasterID",
        1.0                     AS "ConfidenceScore",

        imi."Store_Name",
        imi."Store_Item_ID",
        imi."POSCode",
        imi."ItemName",
        imi."Brand",
        imi."PackSize",
        imi."Category",

        ic.clean_item_name,
        ic.canonical_brand      AS clean_brand,
        ic.clean_pack_size,
        ic.clean_category
    FROM item_master_clustered ic
    JOIN itemmaster_initial imi
      ON ic.raw_item_id = imi.raw_item_id;
    """

    with engine.begin() as conn:
        conn.execute(text(review_sql))
        conn.execute(text(mapping_sql))

build_review_queue_and_mapping(engine)