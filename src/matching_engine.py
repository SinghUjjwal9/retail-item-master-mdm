# -*- coding: utf-8 -*-
"""data_cleaning_raw_data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vcSH2j1J5K7YJHK00EDTYALH1BAxNsn8
"""

# Installing important libraries & Importing from them.
!pip install rapidfuzz
!pip install --upgrade pip
!pip install rapidfuzz==3.6.1
import re
import pandas as pd
from rapidfuzz import fuzz
import random
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity
!pip install flask pyngrok --quiet
from flask import Flask, render_template_string, request, redirect, url_for
from pyngrok import ngrok

engine = create_engine("postgresql+psycopg2://postgres:mypassword@localhost:5432/postgres")


# --- Install PostgreSQL & Python drivers ---
!apt-get -y update
!apt-get -y install postgresql postgresql-contrib
!pip install sqlalchemy psycopg[binary]

# --- Start PostgreSQL service ---
!service postgresql start

# --- Configure PostgreSQL (create user + DB) ---
# Default postgres user has no password; set your own here
PG_USER = "colab_user"
PG_PASS = "colab_pass"
PG_DB   = "colab_db"

# Create user and database
!sudo -u postgres psql -c "DROP DATABASE IF EXISTS {PG_DB};"
!sudo -u postgres psql -c "DROP ROLE IF EXISTS {PG_USER};"
!sudo -u postgres psql -c "CREATE ROLE {PG_USER} WITH LOGIN PASSWORD '{PG_PASS}';"
!sudo -u postgres psql -c "CREATE DATABASE {PG_DB} OWNER {PG_USER};"

# --- SQLAlchemy engine setup ---
from sqlalchemy import create_engine, text

engine = create_engine(
    f"postgresql+psycopg://{PG_USER}:{PG_PASS}@localhost:5432/{PG_DB}",
    echo=True
)
"""
Retail Item Master Project

In this script I implemented the matching logic for new incoming items.
I normalized pack sizes, cleaned text, compared each new item to the existing
central_item_master, and then decided whether to auto-link or send the item
to the review queue.
"""


def normalize_pack_size(size: str) -> str:
    """
    I normalized pack size strings into canonical forms by:
    - Converting L into ML
    - Converting KG into G
    - Unifying different textual variants for litres and grams
    """
    if not isinstance(size, str):
        return ""

    s = size.upper().strip()
    s = s.replace(" ", "")

    # I mapped common textual patterns into standard unit codes.
    s = (
        s.replace("LITERS", "L")
        .replace("LITER", "L")
        .replace("LITRE", "L")
        .replace("LTR", "L")
        .replace("MILLILITRES", "ML")
        .replace("MILLILITER", "ML")
        .replace("MILLILITERS", "ML")
        .replace("MILLILITRE", "ML")
        .replace("GMS", "G")
        .replace("GRAMS", "G")
        .replace("GRAM", "G")
        .replace("GM", "G")
        .replace("KILOGRAMS", "KG")
        .replace("KILOGRAM", "KG")
        .replace("KILO", "KG")
    )

    # I handled the simple cases first.
    if s.endswith("ML"):
        num = s[:-2]
        try:
            val = float(num)
            return f"{int(val)}ML"
        except ValueError:
            return s

    if s.endswith("G"):
        num = s[:-1]
        try:
            val = float(num)
            return f"{int(val)}G"
        except ValueError:
            return s

    # I converted litres to millilitres.
    if s.endswith("L"):
        num = s[:-1]
        try:
            litres = float(num)
            ml = int(round(litres * 1000))
            return f"{ml}ML"
        except ValueError:
            return s

    # I converted kilograms to grams.
    if s.endswith("KG"):
        num = s[:-2]
        try:
            kg = float(num)
            g = int(round(kg * 1000))
            return f"{g}G"
        except ValueError:
            return s

    # If nothing matched, I returned the cleaned string as is.
    return s


def process_new_item(new_item: dict, engine):
    """
    I processed a single new item and tried to match it against central_item_master.

    If the best match was strong enough and pack size matched exactly,
    I auto-linked the item to an existing master and wrote to itemmapping.
    Otherwise, I pushed the item into review_queue for manual review.
    """
    def clean_text(text_val: str) -> str:
        if not isinstance(text_val, str):
            return ""
        s = text_val.upper().strip()
        s = re.sub(r"\s+", " ", s)
        s = re.sub(r"[^A-Z0-9& ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    def extract_brand_family(brand: str) -> str:
        """
        I reduced brand names to a core family where possible
        so that minor suffixes did not affect similarity too much.
        """
        if not brand:
            return brand

        brand_clean = re.sub(
            r"\s+(INC|CORP|COMPANY|LTD|CO|GROUP|INTERNATIONAL)\b",
            "",
            brand,
        ).strip()

        words = brand_clean.split()
        if len(words) > 1 and len(words[0]) <= 4:
            return words[0]
        return brand_clean

    def extract_product_core(name: str) -> str:
        """
        I removed generic modifiers from item names to focus
        on the core product description during similarity checks.
        """
        if not name:
            return name

        modifiers = [
            "PET",
            "BOTTLE",
            "CAN",
            "CLASSIC",
            "ORIGINAL",
            "REGULAR",
            "PREMIUM",
            "DELUXE",
            "SPECIAL",
            "EXTRA",
            "PLUS",
            "MAX",
            "PACK",
            "BUNDLE",
            "SET",
            "COMBO",
            "VALUE",
        ]

        pattern = r"\b(" + "|".join(modifiers) + r")\b"
        core_name = re.sub(pattern, "", name)
        core_name = re.sub(r"\s+", " ", core_name).strip()
        return core_name

    def calculate_contextual_bonus(clean_item, master_item):
        """
        I applied contextual bonuses to the base score if key attributes aligned well
        (exact pack match, token set similarity, brand family similarity, category match).
        """
        bonus = 0.0

        if clean_item["norm_pack"] == master_item["Norm_Pack_Size"]:
            bonus += 0.30

        token_set_sim = fuzz.token_set_ratio(
            clean_item["clean_item_name"], master_item["Master_Item_Name"]
        ) / 100.0
        if token_set_sim >= 0.90:
            bonus += 0.20

        brand_family1 = extract_brand_family(clean_item["clean_brand"])
        brand_family2 = extract_brand_family(clean_text(master_item["Master_Brand"]))
        if brand_family1 and brand_family2:
            if fuzz.ratio(brand_family1, brand_family2) / 100.0 >= 0.80:
                bonus += 0.15

        if clean_item["clean_category"] == clean_text(master_item["Master_Category"]):
            bonus += 0.10

        return bonus

    # I started by cleaning the textual attributes of the incoming item.
    clean_item = {
        "clean_item_name": clean_text(new_item["ItemName"]),
        "clean_brand": clean_text(new_item["Brand"]),
        "clean_pack_size": clean_text(new_item["PackSize"]),
        "clean_category": clean_text(new_item["Category"]),
    }
    clean_item["norm_pack"] = normalize_pack_size(new_item["PackSize"])

    # I loaded the central master into a DataFrame and precomputed normalized pack sizes.
    central_master_df = pd.read_sql("SELECT * FROM central_item_master", engine)
    central_master_df["Norm_Pack_Size"] = central_master_df["Master_Pack_Size"].apply(
        normalize_pack_size
    )

    best_match_id = None
    best_score = 0.0
    best_master_item = None

    # I iterated over each master item and calculated a weighted similarity score.
    for _, master_item in central_master_df.iterrows():
        core_name1 = extract_product_core(clean_item["clean_item_name"])
        core_name2 = extract_product_core(clean_text(master_item["Master_Item_Name"]))

        name_sim1 = fuzz.token_sort_ratio(
            clean_item["clean_item_name"], master_item["Master_Item_Name"]
        ) / 100.0
        name_sim2 = fuzz.token_set_ratio(
            clean_item["clean_item_name"], master_item["Master_Item_Name"]
        ) / 100.0
        name_sim3 = fuzz.ratio(core_name1, core_name2) / 100.0
        name_sim = max(name_sim1, name_sim2, name_sim3)

        brand_family1 = extract_brand_family(clean_item["clean_brand"])
        brand_family2 = extract_brand_family(clean_text(master_item["Master_Brand"]))

        brand_sim1 = fuzz.ratio(
            clean_item["clean_brand"], clean_text(master_item["Master_Brand"])
        ) / 100.0
        brand_sim2 = (
            fuzz.ratio(brand_family1, brand_family2) / 100.0
            if brand_family1 and brand_family2
            else 0.0
        )
        brand_sim = max(brand_sim1, brand_sim2)

        pack_match = 1.0 if clean_item["norm_pack"] == master_item["Norm_Pack_Size"] else 0.0

        base_score = (name_sim * 0.5) + (brand_sim * 0.3) + (pack_match * 0.2)

        contextual_bonus = calculate_contextual_bonus(clean_item, master_item)

        confidence_score = min(1.0, base_score + contextual_bonus)

        if confidence_score > best_score:
            best_score = confidence_score
            best_match_id = master_item["MasterID"]
            best_master_item = master_item

    # I boosted very obvious matches where core name and pack were strongly aligned.
    if best_match_id and best_master_item is not None:
        core1 = extract_product_core(clean_item["clean_item_name"])
        core2 = extract_product_core(clean_text(best_master_item["Master_Item_Name"]))

        pack_match_flag = clean_item["norm_pack"] == best_master_item["Norm_Pack_Size"]
        core_similarity = fuzz.ratio(core1, core2) / 100.0

        if core_similarity >= 0.8 and pack_match_flag:
            best_score = max(best_score, 0.9)

    GOOD_THRESHOLD = 0.85

    if best_match_id is not None and best_master_item is not None:
        final_pack_match = clean_item["norm_pack"] == best_master_item["Norm_Pack_Size"]
    else:
        final_pack_match = False

    # If the match was strong and pack size matched, I auto-linked the item.
    if best_match_id is not None and best_score >= GOOD_THRESHOLD and final_pack_match:
        with engine.begin() as conn:
            conn.execute(
                text(
                    """
                UPDATE central_item_master
                SET "RawItemsCount" = "RawItemsCount" + 1
                WHERE "MasterID" = :mid
            """
                ),
                {"mid": best_match_id},
            )

            result = conn.execute(
                text(
                    """
                SELECT COALESCE(MAX("RawItemID"), 0) + 1 AS next_id
                FROM itemmapping
            """
                )
            )
            next_raw_id = result.scalar()

            conn.execute(
                text(
                    """
                INSERT INTO itemmapping
                ("RawItemID", "MasterID", "ConfidenceScore", "Store_Name", "Store_Item_ID",
                 "POSCode", "ItemName", "Brand", "PackSize", "Category",
                 "clean_item_name", "clean_brand", "clean_pack_size", "clean_category")
                VALUES (:raw_id, :master_id, :confidence, :store_name,
                        :store_item_id, :poscode, :itemname, :brand, :packsize,
                        :category, :clean_name, :clean_brand, :clean_pack,
                        :clean_cat)
            """
                ),
                {
                    "raw_id": next_raw_id,
                    "master_id": best_match_id,
                    "confidence": float(best_score),
                    "store_name": new_item["Store_Name"],
                    "store_item_id": new_item["Store_Item_ID"],
                    "poscode": new_item.get("POSCode"),
                    "itemname": new_item["ItemName"],
                    "brand": new_item["Brand"],
                    "packsize": new_item["PackSize"],
                    "category": new_item["Category"],
                    "clean_name": clean_item["clean_item_name"],
                    "clean_brand": clean_item["clean_brand"],
                    "clean_pack": clean_item["clean_pack_size"],
                    "clean_cat": clean_item["clean_category"],
                },
            )

        return {
            "status": "AUTO_LINKED",
            "action": "Automatically linked to existing master",
            "master_id": best_match_id,
            "score": best_score,
        }

    # Otherwise I routed the item into the review queue.
    with engine.begin() as conn:
        conn.execute(
            text(
                """
            INSERT INTO review_queue
            ("RawItemID", "SuggestedMasterID", "ConfidenceScore", "Status",
             "Store_Name", "Store_Item_ID", "ItemName", "Brand", "PackSize",
             "Category", "clean_item_name", "clean_brand", "clean_pack_size",
             "clean_category")
            VALUES (
                (SELECT COALESCE(MAX("RawItemID"), 0) + 1 FROM review_queue),
                :suggested_id,
                :score,
                'Pending',
                :store_name,
                :store_item_id,
                :itemname,
                :brand,
                :packsize,
                :category,
                :clean_name,
                :clean_brand,
                :clean_pack,
                :clean_cat
            )
        """
            ),
            {
                "suggested_id": best_match_id,
                "score": float(best_score),
                "store_name": new_item["Store_Name"],
                "store_item_id": new_item["Store_Item_ID"],
                "itemname": new_item["ItemName"],
                "brand": new_item["Brand"],
                "packsize": new_item["PackSize"],
                "category": new_item["Category"],
                "clean_name": clean_item["clean_item_name"],
                "clean_brand": clean_item["clean_brand"],
                "clean_pack": clean_item["clean_pack_size"],
                "clean_cat": clean_item["clean_category"],
            },
        )

    return {
        "status": "REVIEW_QUEUE",
        "action": "Sent to review queue for manual decision",
        "master_id": best_match_id,
        "score": best_score,
    }

# For checking the code.

new_item = {
    "Store_Name": "StoreX",
    "Store_Item_ID": "12345",
    "POSCode": "STX-0001",
    "ItemName": "CocaCola 1 Litre Bottle",  # similar name
    "Brand": "Coca Cola",                   # similar brand
    "PackSize": "1L",                       # same pack
    "Category": "Beverages",
}

result = process_new_item(new_item, engine)
print(result)

